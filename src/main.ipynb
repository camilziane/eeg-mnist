{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import datasets, transforms\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataloader import EEG_Dataset, EEG_Spectogram_Dataset, EncodedDataset, LatentDataset\n",
    "\n",
    "from models.cnn import CNNClassifier\n",
    "from models.latent_dim import LatentProjection\n",
    "from models.mnist_basic import MNISTClassifier\n",
    "from models.resnet import ResNetClassifier\n",
    "from models.unet_autoencoder import UNetAutoencoder\n",
    "from models.vgg import VGGish\n",
    "\n",
    "from utils.utils import LossTracker, plot_losses, plot_spectrogram, create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Neither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\nRequirement 'tensorboardX' not met. HINT: Try running `pip install -U 'tensorboardX'`\nRequirement 'tensorboard' not met. HINT: Try running `pip install -U 'tensorboard'`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m logger \u001b[38;5;241m=\u001b[39m \u001b[43mTensorBoardLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlightning_logs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCNN_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/eeg-mnist/.venv/lib/python3.11/site-packages/pytorch_lightning/loggers/tensorboard.py:98\u001b[0m, in \u001b[0;36mTensorBoardLogger.__init__\u001b[0;34m(self, save_dir, name, version, log_graph, default_hp_metric, prefix, sub_dir, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     89\u001b[0m     save_dir: _PATH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     97\u001b[0m ):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_hp_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_hp_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m log_graph \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _TENSORBOARD_AVAILABLE:\n\u001b[1;32m    108\u001b[0m         rank_zero_warn(\n\u001b[1;32m    109\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set `TensorBoardLogger(log_graph=True)` but `tensorboard` is not available.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_TENSORBOARD_AVAILABLE)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/eeg-mnist/.venv/lib/python3.11/site-packages/lightning_fabric/loggers/tensorboard.py:94\u001b[0m, in \u001b[0;36mTensorBoardLogger.__init__\u001b[0;34m(self, root_dir, name, version, default_hp_metric, prefix, sub_dir, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     85\u001b[0m     root_dir: _PATH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     92\u001b[0m ):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _TENSORBOARD_AVAILABLE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _TENSORBOARDX_AVAILABLE:\n\u001b[0;32m---> 94\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     95\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_TENSORBOARDX_AVAILABLE)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_TENSORBOARD_AVAILABLE)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     99\u001b[0m     root_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(root_dir)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: Neither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\nRequirement 'tensorboardX' not met. HINT: Try running `pip install -U 'tensorboardX'`\nRequirement 'tensorboard' not met. HINT: Try running `pip install -U 'tensorboard'`"
     ]
    }
   ],
   "source": [
    "# logger = TensorBoardLogger(\"lightning_logs\", name=\"CNN_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTFIX = \"MNIST_IN\" # or \"MNIST_EP\" \n",
    "train_dataset = load_dataset(f\"DavidVivancos/MindBigData2022_{POSTFIX}\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_eeg_dataset = EEG_Dataset(train_dataset)\n",
    "eeg_train_dataloader, eeg_val_dataloader = create_dataloaders(full_eeg_dataset, batch_size=128, train_split=0.8, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_tracker \u001b[38;5;241m=\u001b[39m LossTracker()\n\u001b[1;32m      2\u001b[0m cnn_classifier \u001b[38;5;241m=\u001b[39m CNNClassifier(input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, sequence_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(logger\u001b[38;5;241m=\u001b[39m\u001b[43mlogger\u001b[49m,max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[loss_tracker])\n\u001b[1;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(cnn_classifier, eeg_train_dataloader, eeg_val_dataloader)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "loss_tracker = LossTracker()\n",
    "cnn_classifier = CNNClassifier(input_channels=5, sequence_length=256, dropout_rate=.2)\n",
    "trainer = Trainer(max_epochs=50, callbacks=[loss_tracker]) # add logger=logger to log to tensorboard\n",
    "trainer.fit(cnn_classifier, eeg_train_dataloader, eeg_val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectogram EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_eeg_spectogram_dataset = EEG_Spectogram_Dataset(train_dataset)\n",
    "eeg_spectogram_train_dataloader, eeg_spectogram_val_dataloader = create_dataloaders(full_eeg_spectogram_dataset, batch_size=128, train_split=0.8, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "loss_tracker = LossTracker()\n",
    "vggish = VGGish()\n",
    "trainer = Trainer(max_epochs=50, callbacks=[loss_tracker])\n",
    "trainer.fit(vggish, eeg_spectogram_train_dataloader, eeg_spectogram_val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"lightning_logs/version_16/checkpoints/epoch=9-step=5220.ckpt\"\n",
    "# autoencoder = CNNAutoencoder.load_from_checkpoint(checkpoint_path)\n",
    "latent_dim = 64\n",
    "loss_tracker = LossTracker()\n",
    "autoencoder = UNetAutoencoder(latent_dim=latent_dim)\n",
    "trainer = Trainer(max_epochs=10, callbacks=[loss_tracker])\n",
    "trainer.fit(autoencoder, eeg_train_dataloader, eeg_val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_full = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "mnist_train_dataset, mnist_val_dataset = random_split(mnist_full, [55000, 5000])\n",
    "mnist_train_loader = DataLoader(mnist_train_dataset, batch_size=64, shuffle=True)\n",
    "mnist_val_loader = DataLoader(mnist_val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"lightning_logs/version_14/checkpoints/epoch=9-step=8600.ckpt\"\n",
    "mnist_classifier = MNISTClassifier.load_from_checkpoint(checkpoint_path)\n",
    "# mnist_classifier = MNISTClassifier(latent_dim=latent_dim)\n",
    "# mnist_trainer = pl.Trainer(max_epochs=3)\n",
    "# mnist_trainer.fit(mnist_classifier, mnist_train_loader, mnist_val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Alignement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_encoder = autoencoder.get_encoder()\n",
    "mnist_encoder = mnist_classifier.feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_train_encoded_dataset = EncodedDataset(eeg_train_dataloader, eeg_encoder)\n",
    "eeg_val_encoded_dataset = EncodedDataset(eeg_val_dataloader, eeg_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_encoded_data = EncodedDataset(mnist_train_loader, mnist_encoder)\n",
    "mnist_val_encoded_data = EncodedDataset(mnist_val_loader, mnist_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_train_dataset = LatentDataset(\n",
    "    eeg_train_encoded_dataset, mnist_train_encoded_data\n",
    ")\n",
    "latent_train_dataloader = DataLoader(latent_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "latent_val_dataset = LatentDataset(eeg_val_encoded_dataset, mnist_train_encoded_data)\n",
    "latent_val_dataloader = DataLoader(latent_val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | projection | Sequential | 58.6 K\n",
      "1 | criterion  | MSELoss    | 0     \n",
      "------------------------------------------\n",
      "58.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.6 K    Total params\n",
      "0.234     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  63%|██████▎   | 1090/1719 [00:11<00:06, 96.98it/s, v_num=2, train_loss_step=11.70, val_loss_step=8.510, val_loss_epoch=11.00, train_loss_epoch=11.00]"
     ]
    }
   ],
   "source": [
    "loss_tracker = LossTracker()\n",
    "latent_projection = LatentProjection(latent_dim,latent_dim)\n",
    "latent_trainer = Trainer(max_epochs=10)\n",
    "latent_trainer.fit(latent_projection, latent_train_dataloader, latent_val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
